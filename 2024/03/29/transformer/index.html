<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/black/pace-theme-corner-indicator.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.zhoujoe.us","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Transformer This is my theoretical note about transformer.">
<meta property="og:type" content="article">
<meta property="og:title" content="transformer">
<meta property="og:url" content="https://www.zhoujoe.us/2024/03/29/transformer/index.html">
<meta property="og:site_name" content="Notes">
<meta property="og:description" content="Transformer This is my theoretical note about transformer.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330011246402.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401215949514.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401220217029.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401221026760.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401221127629.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401221800180.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401232953702.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401233327885.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401234947876.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330014216815.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330153645868.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330155608057.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330162503281.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330170154479.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330210431991.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330211424267.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330212816342.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330224505136.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330225011295.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331142942464.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331175226491.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331182648143.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183316886.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183438277.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183522650.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183547039.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183830230.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331184745355.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401161751867.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330011624817.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401162007211.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401170102876.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401170132117.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401171433805.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401171644393.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401173339550.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401214733916.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401213217461.png">
<meta property="og:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401213202960.png">
<meta property="article:published_time" content="2024-03-29T20:51:24.000Z">
<meta property="article:modified_time" content="2024-04-02T19:09:28.370Z">
<meta property="article:author" content="Joe">
<meta property="article:tag" content="transformer">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330011246402.png">


<link rel="canonical" href="https://www.zhoujoe.us/2024/03/29/transformer/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://www.zhoujoe.us/2024/03/29/transformer/","path":"2024/03/29/transformer/","title":"transformer"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>transformer | Notes</title>
  







<link rel="stylesheet" type="text/css" href="/css/injector/main.css" /><link rel="preload" as="style" href="/css/injector/light.css" /><link rel="preload" as="style" href="/css/injector/dark.css" />
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Notes</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container">
  <div class="algolia-stats"><hr></div>
  <div class="algolia-hits"></div>
  <div class="algolia-pagination"></div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#transformer"><span class="nav-number">1.</span> <span class="nav-text"> Transformer</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#the-whole-frame-of-transformer"><span class="nav-number">1.1.</span> <span class="nav-text"> The whole Frame of Transformer</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#encode-and-decode"><span class="nav-number">1.1.1.</span> <span class="nav-text"> Encode and Decode</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#encode"><span class="nav-number">1.1.1.1.</span> <span class="nav-text"> Encode</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#decode"><span class="nav-number">1.1.2.</span> <span class="nav-text"> Decode</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#pre-training"><span class="nav-number">2.</span> <span class="nav-text"> Pre-Training</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#language-model"><span class="nav-number">2.1.</span> <span class="nav-text"> Language Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#using-neural-network-to-do-predict"><span class="nav-number">2.2.</span> <span class="nav-text"> Using Neural Network to do Predict</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#word-vector"><span class="nav-number">2.2.1.</span> <span class="nav-text"> word vector</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#word2vec"><span class="nav-number">2.2.2.</span> <span class="nav-text"> Word2Vec</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#elmo-model"><span class="nav-number">2.2.3.</span> <span class="nav-text"> ELMO model</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#attention"><span class="nav-number">2.3.</span> <span class="nav-text"> Attention</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#self-attention"><span class="nav-number">2.4.</span> <span class="nav-text"> Self-Attention</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#rnn"><span class="nav-number">2.4.1.</span> <span class="nav-text"> RNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lstm"><span class="nav-number">2.4.2.</span> <span class="nav-text"> LSTM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mask-attention"><span class="nav-number">2.4.3.</span> <span class="nav-text"> Mask Attention</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#multi-head-self-attention"><span class="nav-number">2.4.4.</span> <span class="nav-text"> Multi-head Self-Attention</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#position-embedding"><span class="nav-number">2.5.</span> <span class="nav-text"> Position Embedding</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Joe"
      src="https://avatars.githubusercontent.com/u/91183483?v=4">
  <p class="site-author-name" itemprop="name">Joe</p>
  <div class="site-description" itemprop="description">Festina lente</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">72</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">76</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/DonkeyBoy001" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;DonkeyBoy001" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/profile.php?id=100081303083864" title="FB Page → https:&#x2F;&#x2F;www.facebook.com&#x2F;profile.php?id&#x3D;100081303083864" rel="noopener me" target="_blank"><i class="fab fa-facebook fa-fw"></i>FB Page</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://www.zhoujoe.us/2024/03/29/transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/91183483?v=4">
      <meta itemprop="name" content="Joe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Notes">
      <meta itemprop="description" content="Festina lente">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="transformer | Notes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          transformer
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-29 13:51:24" itemprop="dateCreated datePublished" datetime="2024-03-29T13:51:24-07:00">2024-03-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-02 12:09:28" itemprop="dateModified" datetime="2024-04-02T12:09:28-07:00">2024-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Technical-stack/" itemprop="url" rel="index"><span itemprop="name">Technical stack</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Technical-stack/Meachine-Learning/" itemprop="url" rel="index"><span itemprop="name">Meachine Learning</span></a>
        </span>
    </span>

  
    <span id="/2024/03/29/transformer/" class="post-meta-item leancloud_visitors" data-flag-title="transformer" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>3.6k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>13 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="transformer"><a class="markdownIt-Anchor" href="#transformer"></a> Transformer</h1>
<p>This is my theoretical note about transformer.</p>
<span id="more"></span>
<p>The transformer is the stack of attention.</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330011246402.png" alt></p>
<p><strong>the details of encode sublayer</strong></p>
<blockquote>
<p>encode 和 decode 结构不同</p>
<p>decode 地方多了一个mask</p>
<p>上面的X n是负责 该code N份</p>
</blockquote>
<h2 id="the-whole-frame-of-transformer"><a class="markdownIt-Anchor" href="#the-whole-frame-of-transformer"></a> The whole Frame of Transformer</h2>
<p>seq2seq: from encode to decode</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401215949514.png" alt></p>
<blockquote>
<p>using translation as the example to understand transformer</p>
<blockquote>
<p>Input: Je suis étudiant</p>
<p>Middleware: transformer</p>
<p>Ountput: i am a student</p>
</blockquote>
</blockquote>
<p>the middleware include two parts: encodes and decodes</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401220217029.png" alt></p>
<p>Encode: make the input into an word vector</p>
<p>Decode: generate the translation results, after getting the word vector from encode</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401221026760.png" alt></p>
<p><strong>NX6</strong> means: we gonna using 6 encde to strengthen our word vector</p>
<h3 id="encode-and-decode"><a class="markdownIt-Anchor" href="#encode-and-decode"></a> Encode and Decode</h3>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401221127629.png" alt></p>
<blockquote>
<p>encode includes two sublayer: self-attention, feedforward</p>
<p>There will be one (residual network + normalization) during the transmission of each sublayer.</p>
</blockquote>
<h4 id="encode"><a class="markdownIt-Anchor" href="#encode"></a> Encode</h4>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401221800180.png" alt></p>
<p>Eg:</p>
<p>Using a translation process as case to understand</p>
<blockquote>
<ol>
<li>thinking —&gt; get X1 (word Vector)(green color)</li>
</ol>
<blockquote>
<p>Can be acheived by one-hot, word2Vec</p>
</blockquote>
<p>position coding —&gt; get X1(yellow color)</p>
<blockquote>
<p>Word vector superimposed position encoding</p>
</blockquote>
<ol start="2">
<li>Self attention —&gt; get Z1 (pink color)</li>
</ol>
<blockquote>
<p>z1 has word vectors of positional features, syntactic features, and semantic features</p>
</blockquote>
<ol start="3">
<li>add residual network</li>
</ol>
<blockquote>
<p>residual network to avoid gradient disappears</p>
<blockquote>
<p>W3（W2（W1 X +b1）+b2）+b3</p>
<p>If W1, W2, W3 is particularly small, like 0.0000000000000000.1,</p>
<p>X will disappear</p>
<p>W3（W2（W1 X +b1）+b2）+b3 + X</p>
</blockquote>
</blockquote>
<ol start="4">
<li>layerNorm —&gt; z1</li>
</ol>
<blockquote>
<p>normalization</p>
<p>avoid gradient explosion</p>
</blockquote>
<ol start="5">
<li>Feedforward —&gt; r1</li>
</ol>
<blockquote>
<p>ReLu(W2(w1x + b1) + b2)</p>
<p>The previous step is doing linear transformation, wx+b,</p>
<p><em>the superposition of linear changes is always linear changes.</em></p>
<p><strong>Make a nonlinear transformation</strong> through Relu in Feed Forward to get r1.</p>
<blockquote>
<p>the linear change is the line translation or scale in the space.</p>
<p>the non-linear change make it can fit any state.</p>
<p><em>space translation and space distortion</em></p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>summary</strong></p>
<p>the key of encode is to make the word vector perfect.</p>
<blockquote>
<p>the purpose of encode is to make the computer to understand the world.</p>
</blockquote>
<h3 id="decode"><a class="markdownIt-Anchor" href="#decode"></a> Decode</h3>
<p>The decoder will receive the word vector generated by the encoder, and then generate the translation result.</p>
<p>why we need mask self-attention?</p>
<blockquote>
<p>Training phase：</p>
<p><code> je suis etudiant</code>的翻译结果为 <code>I am a student</code>，</p>
<p>我们把<code>I am a student</code> 的Embedding 输入到 Decoders 里面，翻译第一个词。</p>
<p>如果对 <code>I am a student</code> attention 计算不做 mask， <code>am， a，student</code>对<code>I</code> 的翻译将会有一定的贡献。</p>
<p>如果对 <code>I am a student</code>attention 计算做 mask， <code>am，a，student</code> 对<code>I</code>的翻译将没有贡献。</p>
</blockquote>
<blockquote>
<p>Testing phase：</p>
<p>我们不知道<code>我爱中国</code>的翻译结果为<code>I love China</code></p>
<p>我们只能随机初始化一个 Embedding 输入到 Decoders 里面，翻译第一个词 <code>我</code></p>
<p>无论是否做 mask，<code>Love，China</code>对的翻译都不会产生贡献</p>
<p>但是翻译了第一个词<code>I</code>后，随机初始化的 Embedding 有了<code>I</code>的 Embedding，</p>
<p>也就是说在翻译第二词 <code>love</code> 的时候，<code>I</code>的 Embedding 将有一定的贡献，但是<code>China</code>对<code>love</code> 的翻译毫无贡献，随之翻译的进行，</p>
<p><strong>已经翻译的结果将会对下一个要翻译的词都会有一定的贡献，这就和做了 mask 的训练阶段做到了一种匹配。</strong></p>
</blockquote>
<p>In summary：Decoder does Mask to make the behavior consistent between the training stage and the test stage, so that there is no gap and avoid overfitting.</p>
<blockquote>
<p>encode: K and V</p>
<p>decode: Q</p>
<p>通过 new generated word as the key to do search in encode</p>
</blockquote>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401232953702.png" alt></p>
<blockquote>
<p>The input to the decoder is the new generated word</p>
</blockquote>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401233327885.png" alt></p>
<blockquote>
<p>The linear layer is used to convert the output into the dimension of the vocabulary<br>
Softmax gets the probability of the maximum word</p>
</blockquote>
<p><video src="../../../../../Downloads/ec61d7e6-2356-11eb-9bd3-9e9ae0b32346.mp4"></video></p>
<blockquote>
<p>The above figure dynamically shows how the transformer works</p>
</blockquote>
<p><strong>The different beteween encode and decode</strong></p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401234947876.png" alt></p>
<blockquote>
<p>the decode using encoder-decoder attention</p>
<p>it’s function including two parts:</p>
<blockquote>
<ol>
<li>do mask attention</li>
<li>do cross attention</li>
</ol>
</blockquote>
</blockquote>
<p>why need mask?</p>
<p>In order to solve the gap (mismatch) between the training stage and the test stage.</p>
<p>why encoders give K and V to decoders?</p>
<p>Q comes from decoder</p>
<p>K = V comes from encoder</p>
<p>K = V are source statement</p>
<blockquote>
<p>When we generate this word, we pay attention to the new generated words</p>
<p>and the source statement to determine</p>
<p>which words in the source statement are more effective for the new generated following words.</p>
</blockquote>
<p>以前seq2seq框架是 用 LSTM as encoder and decoder.</p>
<p><em>the essence of Deep Learning is:</em></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><mi>r</mi><mi>e</mi><mi>l</mi><mi>u</mi><mo stretchy="false">(</mo><mi>w</mi><mi>x</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y = relu(wx + b)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span></span></p>
<p><em>The essence of AI model is to find a state in space to find the relationship of items in the real world.</em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bert 就是把 decode 砍掉， 将encode 从6个增加到12个</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>Key concepts or prerequisites of transfomer are listed below.</strong></p>
<hr>
<h1 id="pre-training"><a class="markdownIt-Anchor" href="#pre-training"></a> Pre-Training</h1>
<p>Complete the task B with a small amount of data through a trained model A (using the shallow parameters of model A)</p>
<p>Let’s take an example to understand pre-training</p>
<p>Eg： Application of pre-training in the field of images</p>
<p><em>Utilize General characteristics of CNN shallow layer</em></p>
<blockquote>
<p>I trained a model A through 10w data of geese and ducks, 100-layer CNN</p>
<p>Task B: 100 pictures of cats and dogs, classification - CNN on the 100th floor of the training office, impossible to achieve</p>
<p>Try using the first 50 layers of A and 100 layers to complete task B</p>
<blockquote>
<p>我们有两个相似的任务A和 B，任务 A已经完成了得到了一个模型A</p>
<p>任务B（数据量小）</p>
<p>用到了一个特性：CNN 浅层参数通用</p>
<p>任务B 就可以使用模型 A的浅层参数，后面的参数通过任务B 训练一》1.冻结（浅层参数不变）2.微调（变） 任务B（大数据）可以训练出模型B（我还可以使用模型 A的浅层参数，节省训练时间，节省成本）</p>
</blockquote>
</blockquote>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330014216815.png" alt></p>
<blockquote>
<ol>
<li>
<p>Frozen：The shallow parameters remain unchanged.</p>
</li>
<li>
<p>Fine-Tuning：Shallow parameters will change as task B is trained</p>
</li>
</ol>
</blockquote>
<p><strong>Related technologies</strong></p>
<p>fairseq , transformers Library</p>
<p><strong>Summary</strong></p>
<p>One task A, one task B, the two are very similar.</p>
<p>Task A has trained a model A, using the shallow parameters of model A to train task B, and get model B,</p>
<ol>
<li>Fine-tuning (commonly used) .</li>
<li>Freeze.</li>
</ol>
<h2 id="language-model"><a class="markdownIt-Anchor" href="#language-model"></a> Language Model</h2>
<p>language(人说的话）+Model（表示某个东西，完成某个任务）</p>
<p>tasks</p>
<blockquote>
<ol>
<li>
<p>Comparative Task：Determine which sentence is most likely to appear</p>
<blockquote>
<p>P（&quot;判断这个词的词性”） P（&quot;判断这个词的磁性”）</p>
</blockquote>
</li>
<li>
<p>Prediction Task：predict next word</p>
<blockquote>
<p>判断这个词的<code>___</code></p>
</blockquote>
</li>
</ol>
</blockquote>
<p>使用 链式法则 求出 联合概率</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330153645868.png" alt></p>
<blockquote>
<p>P（w_next |“判断”，“这个”，“词”，“的”）</p>
<p>词库（词典）V-》新华字典，高处一个集合，把所有词装到集合V里</p>
<p>把集合里的每一个词，都进行上一步（1）的计算</p>
<p>词库V=｛“词性”，“火星”}</p>
<p>P（词性|“判断”，“这个”，“词”，”的“）</p>
<p>P（火星|“判断”，“这个”，“词”，“的“）</p>
<p>计算出 哪个词的P最大，就填哪个词</p>
</blockquote>
<p>too much cost for the calculation</p>
<p>we only chose n words from the setence to do calculate</p>
<p>it called n-gram language model</p>
<p><strong>n-gram language model</strong></p>
<p>这里其实用到了Markov chain</p>
<blockquote>
<p>P（词性|”这个”，“词”，”的”</p>
<p>P（火星|”这个”，“词”，“的“）</p>
<p>P（词性|“词”，“的“）</p>
<p>P（火星|“词”，”的“</p>
<p>P（词性I“的“）</p>
<p>P（火星|“的“）</p>
<p>把n个词，取2个词（3元），取3个词（4 元）</p>
</blockquote>
<p>How to calculate the n-gram</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">“词性是动词“</span><br><span class="line">“判断单词的词性” </span><br><span class="line">“磁性很强的磁铁” </span><br><span class="line">“北京的词性是名词“</span><br></pre></td></tr></table></figure>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>词性</mtext><mi mathvariant="normal">∣</mi><mtext>的</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mtext>（词性，的）</mtext></mrow><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mtext>的</mtext><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mn>2</mn><mn>3</mn></mfrac></mrow><annotation encoding="application/x-tex">P(词性 | 的) = \frac{count（词性，的）}{count (的)} = \frac{2}{3}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">词</span><span class="mord cjk_fallback">性</span><span class="mord">∣</span><span class="mord cjk_fallback">的</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.29633em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord cjk_fallback">的</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord cjk_fallback">（</span><span class="mord cjk_fallback">词</span><span class="mord cjk_fallback">性</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">）</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><strong>Smoothing strategy</strong></p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330155608057.png" alt></p>
<p>example to understand the formula</p>
<p>We have a very simple document collection</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;the cat sat on the mat&quot;</span><br><span class="line">&quot;the dog sat on the log&quot;</span><br></pre></td></tr></table></figure>
<p>Vocabulary <em>V</em> will contain the following words:</p>
<blockquote>
<p>{the, cat, sat, on, mat, dog, log}</p>
</blockquote>
<p>The size of the vocabulary |V| is 7</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mi>t</mi><mi>h</mi><mi>e</mi><mo separator="true">,</mo><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mi>t</mi><mi>h</mi><mi>e</mi><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mi>a</mi><mi>t</mi><mi mathvariant="normal">∣</mi><mi>t</mi><mi>h</mi><mi>e</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mi>t</mi><mi>h</mi><mi>e</mi><mo separator="true">,</mo><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn></mrow><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mi>t</mi><mi>h</mi><mi>e</mi><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mn>1</mn></mrow><mrow><mn>2</mn><mo>+</mo><mn>7</mn></mrow></mfrac><mo>=</mo><mfrac><mn>2</mn><mn>9</mn></mfrac></mrow><annotation encoding="application/x-tex">count(the, cat)  = 1
count(the) = 2
P(cat | the)  = \frac{count(the, cat) + 1}{count(the) + |V|} = \frac{1 + 1}{2 + 7} = \frac{2}{9}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord">∣</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.09077em;vertical-align:-0.7693300000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">7</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">9</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<h2 id="using-neural-network-to-do-predict"><a class="markdownIt-Anchor" href="#using-neural-network-to-do-predict"></a> Using Neural Network to do Predict</h2>
<p><strong>one-hot code</strong></p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330162503281.png" alt></p>
<blockquote>
<p>词典V（新华字典里面把所有词集合成一个集合V）</p>
<p>假设词典里面只有8个单词</p>
<p>计算机不认识单词的</p>
<p>但是我们要计算机认识单词</p>
<p>独热编码：给出一个 8*8的矩阵</p>
<p>“time” - 10000000</p>
<p>“fruit” - 01000000</p>
</blockquote>
<p>Usinng <strong>Cosine similarity</strong> calculate the similarity between the two word</p>
<p>in one hot, there is no relationship between each word —&gt; how to improve it</p>
<h3 id="word-vector"><a class="markdownIt-Anchor" href="#word-vector"></a> word vector</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">W1，w2，w3，W4（Unique hot coding of 4 words）</span><br><span class="line">w1*Q=c1，</span><br><span class="line">w2*Q=c2，</span><br><span class="line">w3*Q=c3，</span><br><span class="line">w4*Q=c4，</span><br><span class="line">C=[C1，C2，C3，C4]</span><br><span class="line">Q is a random matrix and a parameter (learnable)</span><br></pre></td></tr></table></figure>
<p>Eg:</p>
<blockquote>
<p>“判断” —&gt; one hot encoding:</p>
<blockquote>
<p>w1［1，0，0，0，0］</p>
</blockquote>
<p>w1*Q =c1（word vector of “判断” ）</p>
</blockquote>
<p>the pros of Word vector:</p>
<ol>
<li>Control the size of dimensions</li>
<li>can express the relationship of two words</li>
</ol>
<h3 id="word2vec"><a class="markdownIt-Anchor" href="#word2vec"></a> Word2Vec</h3>
<p>the main purpose of word2Vec is  to get the word vector</p>
<p>the key of word2Vec is to get Q</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330170154479.png" alt></p>
<p><strong>CBOW</strong></p>
<p>Give the context of a word to predict this word.</p>
<blockquote>
<p>“我是最_的Nick”</p>
<p>帅</p>
</blockquote>
<p><strong>Skip-gram</strong></p>
<p>Give t a word to predict the context of this word.</p>
<blockquote>
<p>“帅”</p>
<p>“我是‘_’Nick”</p>
</blockquote>
<p>the difference beteween CBOW and Skip-gram</p>
<blockquote>
<p>CBOW: 一个老师 告诉 多个学生 Q该怎么变</p>
<p>Skip-gram: 多个老师 告诉一个学生 Q该怎么变</p>
</blockquote>
<p>The cons of word2Vec</p>
<p>Unable to solve the problem <code>one word with multiple meanings</code></p>
<p>Design of Q matrix</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330210431991.png" alt></p>
<blockquote>
<p>00010 代表 apple x Q= 10, 12, 19</p>
<p>apple（<code>苹果（水果）</code>，<code>苹果（手机）</code>）</p>
<p>假设数据集里面的apple 只有<code>苹果（水果）</code>这个意思，没有<code>苹果（手机）</code>这个意思（训练）</p>
<p>（测试，应用）10，12，19 apple，无法表示<code>苹果（手机）</code>这个意思, 因为之前已经训练好了</p>
</blockquote>
<p>word2Vec belongs to the pre-training model.</p>
<blockquote>
<p>Two tasks A and B are given.</p>
<p>Task A has made model A,</p>
<p>and task B can be solved (by using model A to speed up the solution of the task)</p>
</blockquote>
<p>Pre-trained language model（We first use one-hot encoding, then use the Word2Vec pre-trained Q matrix to directly obtain the word vector, and then proceed to the next task)</p>
<blockquote>
<ol>
<li>
<p>Freeze: the Q matrix does not need to be changed</p>
</li>
<li>
<p>Fine-tuning: Change the Q matrix as the task changes</p>
</li>
</ol>
</blockquote>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330211424267.png" alt></p>
<h3 id="elmo-model"><a class="markdownIt-Anchor" href="#elmo-model"></a> ELMO model</h3>
<p>Embeddings Language Models</p>
<p><strong>focus on word vector</strong> , same function as the word2Vec</p>
<p>focus on how to slove mutiple meaning of one word</p>
<blockquote>
<p>Not only training a Q matrix, but also <strong>integrate the contextual information into this Q matrix</strong>.</p>
</blockquote>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330212816342.png" alt></p>
<blockquote>
<p>主要看箭头数据流向的方向 左边的是从上文流向下文 右边是从下文流向上文</p>
<p>左边的LSTM 获取 E2 的上文信息，右边就是下文信息</p>
<p>准备来说 是 时间顺序</p>
</blockquote>
<blockquote>
<p>对比word2Vec 举例子理解</p>
<p>Word2Vec</p>
<blockquote>
<p>x1,x2, x4,x5 --&gt;  x1+x2+x4+x5</p>
</blockquote>
<p>ELMO</p>
<blockquote>
<p>After obtaining the context information, the three layers of information are superimposed</p>
<p>E1+E2+E3 = K1 a new word vector = E1</p>
<blockquote>
<p>K1 contains the word characteristics, syntactic characteristics and semantic characteristics of the first word.</p>
</blockquote>
<p>E2 and E3 are equivalent to two context information.</p>
</blockquote>
<p>Essentially, ELMO is a feature extractor that specializes in word vector extraction, very similar to the backbone in computer vision. Just like VGG-16 or something.</p>
</blockquote>
<p>eg:</p>
<blockquote>
<p>E2, E3 are different, E1+E2+E3 are different</p>
<p>apple -》I ate an apple—》［1，20，10］</p>
<p>apple --》I’m using an apple phone—》［1，10，20］</p>
</blockquote>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330224505136.png" alt></p>
<p>LSTM cannot be parallelized, and long-term dependencies exist and gradients disappear.</p>
<h2 id="attention"><a class="markdownIt-Anchor" href="#attention"></a> Attention</h2>
<p>What will you pay attention to?</p>
<p>Big data (all kinds of data, important and unimportant)</p>
<p>For important data, we need to use</p>
<p>For unimportant data, we don’t want to use</p>
<p>For a model (CNN, LSTM), it is difficult to decide what is important and what is not important.</p>
<p>Based on this, the attention mechanism was born.</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330225011295.png" alt></p>
<blockquote>
<p>If you are given this picture, your eyes will focus on the red area.</p>
<blockquote>
<p>People — at the face</p>
<p>Article — Look at the title of the article.</p>
<p>Article — Look at the beginning of the paragraph.</p>
</blockquote>
</blockquote>
<p>How to implement the self-attention mechanism？</p>
<blockquote>
<p>for example, I look at one picture.</p>
<blockquote>
<p>I (query object Q)</p>
<p>this picture (queried object V)</p>
</blockquote>
<p>Looking at this picture, at first glance,</p>
<p>I will judge which things are more important to me and</p>
<p>which are less important to me (to calculate the importance of things in Q and V)</p>
</blockquote>
<p>the Importance calculation is the similarity calculation (closer).</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mtext>，</mtext><mi>K</mi><mo>=</mo><msub><mi>k</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>3</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>k</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">Q，K = k_1, k_2, k_3,...,k_n
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord cjk_fallback">，</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>Q, K = K1, K2, ••••••, Kn, we generally use the dot product method</p>
<blockquote>
<p>By calculating the similarity of each thing in Q and K by point multiplication,</p>
<p>We can get the similarity of Q and a1, the similarity of Q and a2, and the similarity of Q and an.</p>
</blockquote>
<p>make a softmax layer</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>a</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">softmax(a_1,a_2,...,a_n)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>to get the situation with the highest probability</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331142942464.png" alt></p>
<blockquote>
<p>When you use Q to query, Q has lost its use value, and we will eventually get this picture, but the current picture has more information (more important and less unimportant information)</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>V</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>3</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>v</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V = (v_1, v_2, v_3, ..., v_n)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>（</mtext><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>a</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>∗</mo><mo>+</mo><mo stretchy="false">(</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>v</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><msub><mi>a</mi><mn>1</mn></msub><mo>∗</mo><msub><mi>v</mi><mn>1</mn></msub><mo>+</mo><msub><mi>a</mi><mn>2</mn></msub><mo>∗</mo><msub><mi>v</mi><mn>2</mn></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>a</mi><mi>n</mi></msub><mo>∗</mo><msub><mi>v</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msup><mi>V</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">（a_1,a_2,......,a_n) *+ (v_1,v_2,......,v_n) = (a_1 * v_1 + a_2 * v_2 + ...... + a_n * v_n) = V&#x27;
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback">（</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">+</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.61528em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.61528em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.801892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>This new V’ contains more important and less unimportant information,</p>
<p>replaces V’ with V.</p>
</blockquote>
<p>Attention is putting our attention on more important items.</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331175226491.png" alt></p>
<blockquote>
<p>Q * K ----&gt; MatMul</p>
<blockquote>
<p>Q times K to get similarity</p>
</blockquote>
<p>make a scale based to MatMul —&gt; Scale</p>
<blockquote>
<p>sacle is to avoid extreme situations</p>
</blockquote>
<p>Scale get softMax to get a probablity</p>
<p>probablity * V ----&gt; MatMul</p>
</blockquote>
<p>The new vector represents K and V（K == V）</p>
<p>and this representation also implies the information of Q.</p>
<blockquote>
<p>For Q, the most important information in K</p>
</blockquote>
<h2 id="self-attention"><a class="markdownIt-Anchor" href="#self-attention"></a> Self-Attention</h2>
<p>The key point of self-attention is:</p>
<p>K V Q come from same X</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>K</mi><mo>≈</mo><mi>V</mi><mo>≈</mo><mi>Q</mi></mrow><annotation encoding="application/x-tex">K \approx V \approx Q
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span></span></p>
<p>we get Q K V based on X</p>
<p>Just use different linear changes</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>K</mi><mo>=</mo><mi>X</mi><mo>∗</mo><msub><mi>W</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">K = X * W_k
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>V</mi><mo>=</mo><mi>X</mi><mo>∗</mo><msub><mi>W</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">V = X * W_v
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>V</mi><mo>=</mo><mi>X</mi><mo>∗</mo><msub><mi>W</mi><mi>V</mi></msub></mrow><annotation encoding="application/x-tex">V = X * W_V
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331182648143.png" alt></p>
<p>Then use <em>attention mechanism</em> to get the new Vector Z</p>
<p>This new Z will contain correlation degree beteween itself and other words in the sentence</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183316886.png" alt></p>
<p>**summary **</p>
<ol>
<li>get Q V K</li>
</ol>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183438277.png" alt></p>
<ol start="2">
<li>
<p>Matmul:</p>
<p>get attention score</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183522650.png" alt></p>
</li>
<li>
<p>scale + softmax</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183547039.png" alt></p>
</li>
<li>
<p>matmul:</p>
<p>rerrange the new vector</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331183830230.png" alt></p>
</li>
</ol>
<blockquote>
<p>通过 thinking machines</p>
<p>调整 thinking的新向量</p>
<blockquote>
<p>对于thinking， 初始词向量为x1</p>
<p>现在我通过 thinking machines 这句话 查询 这句话里面的 每一个单词 和 thinking 之间的 相似度。</p>
</blockquote>
<p>新的z1仍然是 thinking词向量的表示，只不过这个词向量 蕴含了 thinking machines这句话的信息。</p>
</blockquote>
<p>Take an example to explain the self-attention</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240331184745355.png" alt></p>
<blockquote>
<p>Without self-attention,<code> its</code> word vector is simply its without any additional information.</p>
<p>The new <code>its</code> word vector obtained through the self-attention mechanism will contain the information of <code>laws </code>and <code>application</code> .</p>
</blockquote>
<p><strong>summary</strong></p>
<p>Attention:</p>
<blockquote>
<p>Assuming K==V, then Q is multiplied by K  to find similarity A, and then A is multiplied by V  to get the attention value Z, which is another form of representation of V.</p>
</blockquote>
<p>self-attention:</p>
<blockquote>
<p>Q K V comes from the same sources</p>
</blockquote>
<p>Cross-attention:</p>
<blockquote>
<p>Q and V come from different sources</p>
<p>K and V come from same sources</p>
</blockquote>
<h3 id="rnn"><a class="markdownIt-Anchor" href="#rnn"></a> RNN</h3>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401161751867.png" alt></p>
<blockquote>
<p>由于链数的增加，导致前期 X0的占比越来越少，</p>
<p>尤其是当Xt比较大，链子比较长，X0的信息基本上就没了。</p>
<p>eg: 50字左右</p>
</blockquote>
<p>RNN Shared parameters</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240330011624817.png" alt></p>
<blockquote>
<p>U W V share a set of parameters</p>
</blockquote>
<p>Why does RNN have gradient disappear?</p>
<blockquote>
<p>The gradient disappearance of RNN is different from other neural networks.</p>
<p>The gradient of RNN is a total gradient</p>
<p>它的梯度消失并不是变为0，而是说 总的梯度 被 近距离的梯度主导，被远距离的梯度忽略不计。</p>
<p>Its gradient disappears not to 0, but the total gradient is dominated by the gradient at a short distance and is ignored by the gradient at a long distance.</p>
</blockquote>
<p>Transformers are processed in parallel instead of one by one.</p>
<h3 id="lstm"><a class="markdownIt-Anchor" href="#lstm"></a> LSTM</h3>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401162007211.png" alt></p>
<blockquote>
<p>通过增加 遗忘门，等 门，选择性的记忆以前的信息</p>
<p>Eg: 200字左右</p>
</blockquote>
<p>Attention 和 RNN 区别</p>
<p>RNNs have long sequence dependency problems and <strong>cannot be parallelized.</strong></p>
<h3 id="mask-attention"><a class="markdownIt-Anchor" href="#mask-attention"></a> Mask Attention</h3>
<p>你能计算每个单词之间的相似度，这个任务生成文本，一个个单词生成，你没法计算每个单词之间的相似度，因为当生成l时还没有have呢</p>
<p>before mask</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401170102876.png" alt></p>
<blockquote>
<p>Given an X, get a Z through the self-attention model.</p>
<p>This Z is a new representation of X (word vector).</p>
</blockquote>
<p>after mask</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401170132117.png" alt></p>
<blockquote>
<p>The self-attention mechanism clearly knows how many words there are in this sentence and gives them all at once.</p>
<p>The masks attention is given in batches, and the full amount is given at the last time.</p>
</blockquote>
<h3 id="multi-head-self-attention"><a class="markdownIt-Anchor" href="#multi-head-self-attention"></a> Multi-head Self-Attention</h3>
<p>The number of Multi-head is represented by h, generally h=8,</p>
<p>and we usually use the 8-head self-attention mechanism.</p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401171433805.png" alt></p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401171644393.png" alt></p>
<blockquote></blockquote>
<p>The essence of machine learning：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>w</mi><mi>x</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y  = \sigma(wx + b)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span></span></p>
<p>What is the above function doing?</p>
<p>Through non-linear changes, trains the model to make something that seems unreasonable to be reasonable.</p>
<p>What is the nature of nonlinear transformation?</p>
<p>Change the position coordinates on the space, and any point can be found in the dimension space.</p>
<p>Through certain means, an unreasonable point (unreasonable position) can be made reasonable.</p>
<blockquote>
<p>one-hot coding （0101010）</p>
<p>word2vec (11， 222， 33)</p>
<p>emlo (15， 3， 2)</p>
<p>attention (124， 2， 32)</p>
<p>multi-head attention （1231，23，3）</p>
<blockquote>
<p>Cuting X into 8 pieces,</p>
<p>In this way, an X that was originally in one position went to 8 positions in space.</p>
<p>By searching for 8 points, a more suitable position was found.</p>
</blockquote>
<p>My personal understanding is： <strong>Describing the item through the current single feature is not enough to differentiate. Add more different features to describe the thing, thereby increasing the distinction.</strong></p>
</blockquote>
<p><strong>The Flow Chart of Multi-head Graph</strong></p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401173339550.png" alt></p>
<p><strong>summary</strong></p>
<p>the pros and cons of attention</p>
<p>Pros:</p>
<blockquote>
<ol>
<li>solve long sequence dependency problem</li>
<li>Problems can be solved in parallel</li>
</ol>
</blockquote>
<p>Cons:</p>
<blockquote>
<ol>
<li>no relationship beteween each word</li>
</ol>
<blockquote>
<p>There is <strong>no sequential relationship between words</strong></p>
</blockquote>
</blockquote>
<h2 id="position-embedding"><a class="markdownIt-Anchor" href="#position-embedding"></a> Position Embedding</h2>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401214733916.png" alt></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mi mathvariant="normal">/</mi><mn>100</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant="normal">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE(pos, 2i) = sin(pos/1000^{2i/d_{model}})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord">/</span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mord mtight">/</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mi mathvariant="normal">/</mi><mn>100</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mi mathvariant="normal">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE(pos, 2i + 1) = cos(pos/1000^{2i+1/d_{model}})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord">/</span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mord mtight">/</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<blockquote>
<p>i is the index of dimension</p>
<p>d is the dimension</p>
</blockquote>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401213217461.png" alt></p>
<p><img src="https://f005.backblazeb2.com/file/joejoejoe9527123/2024-04-02-image-20240401213202960.png" alt></p>
<p>Properties of trigonometric functions</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>α</mi><mo>+</mo><mi>β</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mi>i</mi><mi>n</mi><mi>α</mi><mi>c</mi><mi>o</mi><mi>s</mi><mi>β</mi><mo>+</mo><mi>c</mi><mi>o</mi><mi>s</mi><mi>α</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>β</mi></mrow><annotation encoding="application/x-tex">sin(α + β) = sinαcosβ + cosαsinβ
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy="false">(</mo><mi>α</mi><mo>+</mo><mi>β</mi><mo stretchy="false">)</mo><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mi>α</mi><mi>c</mi><mi>o</mi><mi>s</mi><mi>β</mi><mo>−</mo><mi>s</mi><mi>i</mi><mi>n</mi><mi>α</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>β</mi></mrow><annotation encoding="application/x-tex">cos(α + β) = cosαcosβ - sinαsinβ
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span></p>
<p class="katex-block katex-error" title="ParseError: KaTeX parse error: Can&#039;t use function &#039;\textcircled&#039; in math mode at position 14: \html@mathml{\̲t̲e̲x̲t̲c̲i̲r̲c̲l̲e̲d̲{\scriptsize R}…">PE(pos + k, 2i) = PE(pos,2i) ✖️ PE(k, 2i + 1) + PE(pos, 2i + 1) ✖️ PE(k, 2i)
</p>
<p class="katex-block katex-error" title="ParseError: KaTeX parse error: Can&#039;t use function &#039;\textcircled&#039; in math mode at position 14: \html@mathml{\̲t̲e̲x̲t̲c̲i̲r̲c̲l̲e̲d̲{\scriptsize R}…">PE(pos + k, 2i + 1) =PE(pos,2i + 1) ✖️ PE(k, 2i + 1) - PE(pos, 2i) ✖️ PE(k, 2i)
</p>
<blockquote>
<p>the even position using sin function</p>
<p>the odd position using cos function</p>
</blockquote>
<p>Eg:</p>
<p>pos + k = 5, When we calculate the position code of the fifth word</p>
<p>pos = 1, k = 4,     the pos 5 has linear relationship with pos1 and pos4</p>
<p>Pos = 2, k = 3,     the pos 5 has linear relationship with pos2 and pos3</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sin(postk) = sin(pos)*cos(k) + cos(pos)*sin(k) # sin represents the even dimension.</span><br><span class="line">cos(pos+k) = cos(pos)*cos(k) - sin(pos)*sin(k) # cos represents the odd dimension.</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/transformer/" rel="tag"># transformer</a>
              <a href="/tags/LLM/" rel="tag"># LLM</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/03/28/cookerandsession/" rel="prev" title="Cookie, Session and Token">
                  <i class="fa fa-angle-left"></i> Cookie, Session and Token
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/04/02/codeTransformer/" rel="next" title="codeTransformer">
                  codeTransformer <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Joe</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">271k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">16:25</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

<!--
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>-->

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

  <a href="https://github.com/DonkeyBoy001" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/algoliasearch/4.20.0/algoliasearch-lite.umd.js" integrity="sha256-DABVk+hYj0mdUzo+7ViJC6cwLahQIejFvC+my2M/wfM=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/instantsearch.js/4.57.0/instantsearch.production.min.js" integrity="sha256-foJtB+Wd0wvvK+VU3KO0/H6CjwSwJfB1RnWlgx0Ov9U=" crossorigin="anonymous"></script><script src="/js/third-party/search/algolia-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"rZsuavEmZYP4PEa5niaZG6rn-MdYXbMMI","app_key":"iv0iSNLUTfYodhD0RwdwW9bn","server_url":null,"security":true}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script>
((window.gitter = {}).chat = {}).options = {
  room: 'your-room-name',
  activationElement: false
};
</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script><div class="moon-menu">
  <div class="moon-menu-items">
    
    <div id="moon-menu-item-back2bottom" class="moon-menu-item">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div id="moon-menu-item-back2top" class="moon-menu-item">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>
